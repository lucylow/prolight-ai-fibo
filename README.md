# ProLight AI - Professional Lighting Simulator

<div align="center">

![ProLight AI](https://img.shields.io/badge/ProLight-AI-blue?style=for-the-badge&logo=ai&logoColor=white)
![FIBO Hackathon](https://img.shields.io/badge/FIBO-Hackathon-orange?style=for-the-badge&logo=hackathon&logoColor=white)
![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge&logo=opensourceinitiative&logoColor=white)
![TypeScript](https://img.shields.io/badge/TypeScript-5.8-blue?logo=typescript&logoColor=white)
![React](https://img.shields.io/badge/React-18.3-blue?logo=react&logoColor=white)
![Deno](https://img.shields.io/badge/Deno-1.40-black?logo=deno&logoColor=white)

**Precision Lighting, Powered by FIBO**

[Demo](#-demo) ‚Ä¢ [Features](#-key-features) ‚Ä¢ [Installation](#Ô∏è-installation) ‚Ä¢ [API](#-api-documentation) ‚Ä¢ [Architecture](#Ô∏è-system-architecture) ‚Ä¢ [Use Cases](#-use-cases) ‚Ä¢ [FAQ](#-frequently-asked-questions) ‚Ä¢ [Contributing](#-contributing)

</div>

## üéØ Overview

ProLight AI is a production-grade studio lighting simulator that bridges the gap between photographic expertise and AI image generation. By leveraging **BRIA FIBO's JSON-native architecture**, we replace unpredictable text prompts with precise, professional lighting parameters‚Äîenabling perfect studio setups in seconds without expensive equipment.

> **Innovation**: Unlike traditional AI image generators that rely on ambiguous text prompts, ProLight AI provides deterministic control through structured JSON parameters, giving photographers and creators reproducible, professional-grade results with seed-based reproducibility.

### Technical Highlights

- **Edge Computing**: Supabase Edge Functions (Deno runtime) for sub-100ms API responses
- **Type-Safe Architecture**: Full TypeScript implementation with strict type checking
- **Real-Time 3D Visualization**: Three.js + React Three Fiber for 60 FPS lighting previews
- **Deterministic Generation**: FIBO JSON schema ensures reproducible results with seed values
- **Natural Language Processing**: Google Gemini AI for converting descriptions to structured parameters
- **Production-Ready**: Error handling, validation, rate limiting, and comprehensive logging

## üé¨ Demo

### Live Demo
- **Production URL**: [Coming Soon]
- **Staging Environment**: [Coming Soon]

### Demo Features
- **Interactive 3D Studio**: Real-time lighting visualization with Three.js
- **Natural Language Input**: Describe your lighting setup in plain English
- **Professional Presets**: One-click application of classic lighting patterns
- **Image Generation**: Generate high-quality images with deterministic results
- **Analysis Dashboard**: Real-time lighting metrics and professional ratings

### Screenshots & Videos
> **Note**: Add screenshots and demo videos to showcase the application. Consider including:
> - 3D lighting visualization interface
> - Natural language input examples
> - Generated image gallery
> - Analysis dashboard with metrics

### Quick Demo Script
1. **Start with a Preset**: Select "Rembrandt" from the presets menu
2. **Adjust Parameters**: Modify intensity, color temperature, and softness
3. **View 3D Preview**: See real-time updates in the 3D visualization
4. **Generate Image**: Click "Generate" and wait 2-4 seconds
5. **Analyze Results**: Review the professional rating and recommendations

## üöÄ Key Features

### üé® **Professional Lighting Control**

- **Multi-Point Lighting System**: Key, fill, rim, and ambient light controls with independent parameterization
- **Real-time 3D Visualization**: Interactive Three.js preview with directional light helpers and shadow visualization
- **Precise Parameter Control**: 
  - Intensity: 0.0-1.0 normalized scale
  - Color Temperature: 2500K-10000K (Kelvin)
  - Softness: 0.0-1.0 (hard to soft light)
  - Distance: 0.5-5.0 meters (inverse square falloff)
  - Direction: Spherical coordinates (azimuth, elevation) or photographic descriptions
- **Professional Presets**: Butterfly, Rembrandt, dramatic fashion, soft portrait, split lighting, and clamshell setups
- **Lighting Ratio Analysis**: Real-time key-to-fill ratio calculation with professional style classification

### ü§ñ **FIBO JSON-Native Integration**

- **Structured JSON Generation**: Convert natural language to precise FIBO JSON schemas via Gemini AI
- **Deterministic Results**: Same parameters + seed = identical output every time
- **Parameter Disentanglement**: Modify individual lighting elements without affecting others
- **Three Operation Modes**: 
  - **Generate**: Direct lighting parameter control
  - **Refine**: Iterative parameter adjustment
  - **Inspire**: Natural language to structured conversion
- **FIBO Schema Compliance**: Full adherence to BRIA FIBO specification with validation

### üìä **Advanced Analysis**

- **Lighting Ratio Calculator**: Real-time key-to-fill ratio analysis (1:1 to 8:1+)
- **Professional Rating System**: AI-powered quality assessment (1-10 scale) based on:
  - Lighting balance and contrast
  - Color temperature harmony
  - Shadow detail preservation
  - Professional style adherence
- **Color Harmony Analysis**: Temperature consistency and mood assessment
- **Technical Recommendations**: Expert suggestions for improvement based on photographic principles

### üéÆ **Premium User Experience**

- **Glass Morphism UI**: Modern, professional interface with backdrop blur effects
- **Real-time Previews**: Instant 3D visualization of lighting changes (60 FPS target)
- **Drag & Drop Controls**: Intuitive parameter adjustment with visual feedback
- **Responsive Design**: Works seamlessly on desktop, tablet, and mobile devices
- **Dark Mode Support**: System-aware theme switching with smooth transitions

### üé• **Video Editing & Post-Processing**
- **Background Removal**: Remove backgrounds from generated images
- **Upscaling**: Enhance image resolution with AI-powered upscaling
- **Foreground Masking**: Advanced masking for precise edits
- **Real-time Status Updates**: Server-Sent Events (SSE) for job progress
- **Batch Processing**: Process multiple images simultaneously

### üé® **Tailored Generation**
- **Custom Model Training**: Train models on your own image datasets
- **Brand-Specific Generation**: Generate images matching your brand style
- **Dataset Management**: Upload and organize training images
- **ControlNet Support**: Canny, depth, recoloring, and color grid guidance
- **Image Prompt Adapter**: Style transfer and reference-based generation
- **Reimagine**: Transform images with structure and portrait references

### üîß **Backend API Features**
- **FastAPI REST API**: High-performance Python backend
- **Comprehensive Endpoints**: Generate, presets, history, batch, analysis
- **Mock Data Support**: Development without API keys
- **Batch Operations**: Generate multiple variations efficiently
- **Lighting Analysis**: Professional quality assessment
- **History Management**: Track and manage generation history

## üèóÔ∏è System Architecture

### High-Level Architecture

```mermaid
graph TB
    subgraph "Client Layer"
        Browser[Web Browser<br/>React 18 + TypeScript]
        CDN[Vercel CDN<br/>Static Assets]
    end
    
    subgraph "Edge Computing Layer"
        EdgeFn[Supabase Edge Functions<br/>Deno 1.40 Runtime]
        EdgeFn1[generate-lighting<br/>POST /generate-lighting]
        EdgeFn2[natural-language-lighting<br/>POST /natural-language-lighting]
        EdgeFn3[analyze-lighting<br/>POST /analyze-lighting]
        EdgeFn4[video-editing<br/>POST /video-editing]
    end
    
    subgraph "External APIs"
        BRIA[BRIA FIBO API<br/>Image Generation]
        Gemini[Google Gemini API<br/>Natural Language Processing]
    end
    
    subgraph "Storage & Database"
        SupabaseStorage[Supabase Storage<br/>Generated Images]
        SupabaseDB[(Supabase PostgreSQL<br/>User Sessions & Metadata)]
    end
    
    Browser --> CDN
    Browser --> EdgeFn
    
    EdgeFn --> EdgeFn1
    EdgeFn --> EdgeFn2
    EdgeFn --> EdgeFn3
    EdgeFn --> EdgeFn4
    
    EdgeFn1 --> BRIA
    EdgeFn2 --> Gemini
    EdgeFn2 --> BRIA
    EdgeFn3 --> SupabaseDB
    
    BRIA --> SupabaseStorage
    EdgeFn1 --> SupabaseStorage
    EdgeFn2 --> SupabaseStorage
    
    style Browser fill:#e1f5ff
    style EdgeFn fill:#fff4e1
    style BRIA fill:#ffe1f5
    style SupabaseStorage fill:#e1ffe1
```

### Data Flow Architecture

```mermaid
flowchart TB
    Start([User Input]) --> InputType{Input Type?}
    
    InputType -->|3D Lighting Setup| LightingUI[Lighting Controls UI<br/>React Components]
    InputType -->|Natural Language| NLInput[Natural Language Input<br/>Text Area]
    
    LightingUI --> LightingStore[Zustand State Store<br/>useLightingStore]
    NLInput --> Gemini[Gemini AI<br/>NL to JSON Conversion]
    
    Gemini --> LightingStore
    LightingStore --> FIBOMapper[FIBO JSON Mapper<br/>TypeScript Utils]
    
    FIBOMapper --> Validation[FIBO Schema Validation<br/>Type Guards & Zod]
    Validation --> Analysis[Lighting Analysis Engine<br/>Ratio Calculation]
    Analysis --> FIBOJSON[Structured FIBO JSON<br/>Validated Schema]
    
    FIBOJSON --> SupabaseFn[Supabase Edge Function<br/>Deno HTTP Handler]
    SupabaseFn --> BRIAAPI[BRIA FIBO API<br/>REST Endpoint]
    
    BRIAAPI --> ImageGen[Image Generation<br/>2-4 seconds]
    ImageGen --> Result[Generated Image<br/>URL + Metadata]
    
    Result --> Preview[3D Preview Update<br/>React Three Fiber]
    Result --> AnalysisDash[Analysis Dashboard<br/>Real-time Metrics]
    
    Preview --> End([User Feedback])
    AnalysisDash --> End
    
    style LightingUI fill:#e1f5ff
    style NLInput fill:#e1f5ff
    style FIBOJSON fill:#fff4e1
    style BRIAAPI fill:#ffe1f5
    style Result fill:#e1ffe1
```

### Request Sequence Diagram

```mermaid
sequenceDiagram
    participant User
    participant Frontend as React Frontend
    participant EdgeFn as Supabase Edge Function
    participant Gemini as Google Gemini API
    participant BRIA as BRIA FIBO API
    participant Storage as Supabase Storage
    
    User->>Frontend: Adjust Lighting Parameters
    Frontend->>Frontend: Update Zustand Store
    Frontend->>Frontend: Update 3D Visualization (Three.js)
    Frontend->>Frontend: Calculate Lighting Ratios
    
    User->>Frontend: Generate Image
    Frontend->>EdgeFn: POST /generate-lighting<br/>{lightingSetup, cameraSettings, ...}
    
    EdgeFn->>EdgeFn: Validate Request Body
    EdgeFn->>EdgeFn: Build FIBO JSON Schema
    EdgeFn->>EdgeFn: Analyze Lighting Setup<br/>(Key-to-Fill Ratio)
    
    alt Natural Language Mode
        EdgeFn->>Gemini: POST /v1/models/gemini-pro<br/>{systemPrompt, userPrompt}
        Gemini-->>EdgeFn: Structured Lighting JSON
        EdgeFn->>EdgeFn: Validate & Transform
    end
    
    EdgeFn->>BRIA: POST /v2/generate<br/>{fibo_json, steps, guidance_scale}
    BRIA-->>EdgeFn: {image_url, seed, metadata}
    
    EdgeFn->>Storage: Upload Image (if needed)
    EdgeFn->>EdgeFn: Analyze Generated Image
    EdgeFn-->>Frontend: {imageUrl, analysis, fiboJson, seed}
    
    Frontend->>Frontend: Update Image Preview
    Frontend->>Frontend: Display Analysis Dashboard
    Frontend-->>User: Show Generated Image + Metrics
```

### Technology Stack

| Layer | Technology | Version | Purpose |
|-------|------------|---------|---------|
| **Frontend Framework** | React | 18.3.1 | Modern UI framework with concurrent features |
| **Type System** | TypeScript | 5.8.3 | Type safety and developer experience |
| **3D Graphics** | Three.js | 0.160.1 | WebGL-based 3D rendering |
| **3D React Integration** | React Three Fiber | 8.18.0 | React renderer for Three.js |
| **3D Helpers** | React Three Drei | 9.122.0 | Useful helpers and abstractions |
| **State Management** | Zustand | 4.5.7 | Lightweight state management |
| **Data Fetching** | TanStack Query | 5.83.0 | Server state management and caching |
| **UI Components** | Radix UI | Latest | Accessible component primitives |
| **Styling** | Tailwind CSS | 3.4.17 | Utility-first CSS framework |
| **Animations** | Framer Motion | 10.18.0 | Production-ready motion library |
| **Routing** | React Router | 6.30.1 | Declarative routing for React |
| **Form Handling** | React Hook Form | 7.61.1 | Performant forms with validation |
| **Validation** | Zod | 3.25.76 | TypeScript-first schema validation |
| **Build Tool** | Vite | 5.4.19 | Next-generation frontend tooling |
| **Edge Runtime** | Deno | 1.40 | TypeScript-native runtime for edge functions |
| **Edge Functions** | Supabase Edge Functions | Latest | Serverless functions on Deno |
| **AI/ML** | BRIA FIBO API | v2 | Structured image generation |
| **NLP** | Google Gemini | Latest | Natural language processing |
| **Database** | Supabase PostgreSQL | Latest | Relational database with real-time |
| **Storage** | Supabase Storage | Latest | Object storage for images |
| **Deployment** | Vercel | Latest | Frontend deployment platform |
| **CI/CD** | GitHub Actions | Latest | Automated testing and deployment |

## üõ†Ô∏è Installation

### Prerequisites

- **Node.js** 18+ and **npm** 9+ (or **bun** 1.0+)
- **Deno** 1.40+ (for local edge function development)
- **Supabase CLI** (for edge function deployment)
- **Git** for version control

### Quick Start

```bash
# Clone the repository
git clone https://github.com/your-username/prolight-ai-fibo.git
cd prolight-ai-fibo

# Install dependencies
npm install
# or
bun install

# Set up environment variables
cp .env.example .env
# Edit .env with your API keys

# Start development server
npm run dev
# or
bun run dev
```

The application will be available at `http://localhost:8080` (configurable in `vite.config.ts`).

### Backend Setup

The backend is a FastAPI application that provides additional API endpoints and features:

```bash
# Navigate to backend directory
cd backend

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Copy environment configuration
cp .env.example .env
# Edit .env with your API keys

# Run the server
python -m app.main
# Or using uvicorn directly
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

The backend API will be available at `http://localhost:8000` with interactive documentation at:
- **Swagger UI**: `http://localhost:8000/docs`
- **ReDoc**: `http://localhost:8000/redoc`

### Docker Setup (Recommended)

For a complete setup with both frontend and backend:

```bash
# Start all services with Docker Compose
docker-compose up -d

# View logs
docker-compose logs -f

# Stop services
docker-compose down
```

This will start:
- Frontend: `http://localhost:5173`
- Backend API: `http://localhost:8000`
- Database: PostgreSQL (if configured)

### Environment Variables

Create a `.env` file in the root directory:

```env
# Supabase Configuration
VITE_SUPABASE_URL=https://your-project.supabase.co
VITE_SUPABASE_ANON_KEY=your-anon-key

# BRIA API Configuration
BRIA_API_KEY=your_bria_api_key_here
BRIA_API_URL=https://api.bria.ai/v2

# Google Gemini API
GEMINI_API_KEY=your_gemini_api_key_here

# Application Configuration
VITE_APP_NAME=ProLight AI
VITE_API_URL=http://localhost:54321/functions/v1

# Build Information (auto-generated)
VITE_BUILD_TIME=2025-01-XX
VITE_COMMIT_HASH=abc1234
```

**Backend Environment Variables** (`.env` in `backend/` directory):

```env
# FIBO API Configuration
FIBO_API_KEY=your_bria_api_key_here
USE_MOCK_FIBO=True  # Set to False to use real FIBO API

# Google Gemini API (Optional)
GEMINI_API_KEY=your_gemini_api_key_here

# Database Configuration
DATABASE_URL=sqlite:///./prolight.db
# Or PostgreSQL: postgresql://user:password@localhost:5432/prolight

# CORS Configuration
CORS_ORIGINS=["http://localhost:5173","http://localhost:3000","http://localhost:8080"]

# Server Configuration
HOST=0.0.0.0
PORT=8000
DEBUG=False

# AWS S3 (for image uploads, optional)
AWS_ACCESS_KEY_ID=your_access_key
AWS_SECRET_ACCESS_KEY=your_secret_key
AWS_REGION=us-east-1
S3_BUCKET_NAME=prolight-images

# Stripe (for payments, optional)
STRIPE_SECRET_KEY=your_stripe_secret_key
STRIPE_PUBLISHABLE_KEY=your_stripe_publishable_key
```

### Supabase Edge Functions Setup

```bash
# Install Supabase CLI
npm install -g supabase

# Login to Supabase
supabase login

# Link to your project
supabase link --project-ref your-project-ref

# Deploy edge functions
supabase functions deploy generate-lighting
supabase functions deploy natural-language-lighting
supabase functions deploy analyze-lighting
supabase functions deploy video-editing

# Set secrets for edge functions
supabase secrets set BRIA_API_KEY=your_key
supabase secrets set GEMINI_API_KEY=your_key
```

### Local Edge Function Development

```bash
# Start Supabase locally
supabase start

# Serve edge functions locally
supabase functions serve generate-lighting --env-file .env.local

# Test edge function
curl -X POST http://localhost:54321/functions/v1/generate-lighting \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_ANON_KEY" \
  -d '{"subjectDescription": "test", "environment": "studio", ...}'
```

## üìö API Documentation

### Supabase Edge Functions

All edge functions are deployed to Supabase and accessible via:
```
https://{project-ref}.supabase.co/functions/v1/{function-name}
```

#### Generate Image from Lighting Setup

**Endpoint:** `POST /functions/v1/generate-lighting`

**Request Headers:**
```http
Content-Type: application/json
Authorization: Bearer {supabase_anon_key}
```

**Request Body:**
```typescript
interface SceneRequest {
  subjectDescription: string;        // Required: Subject description
  environment: string;                // Required: Environment/scene description
  lightingSetup: {
    key?: LightSettings;
    fill?: LightSettings;
    rim?: LightSettings;
    ambient?: LightSettings;
  };
  cameraSettings: {
    shotType: string;                 // e.g., "close-up", "medium shot"
    cameraAngle: string;              // e.g., "eye-level", "high angle"
    fov: number;                      // Field of view (10-180 degrees)
    lensType: string;                  // e.g., "portrait", "wide-angle"
    aperture: string;                 // e.g., "f/2.8", "f/11"
  };
  stylePreset?: string;               // Optional: Preset name
  enhanceHDR?: boolean;              // Optional: Enable HDR enhancement
  negativePrompt?: string;            // Optional: Negative prompt
}

interface LightSettings {
  direction: string;                  // Photographic direction description
  intensity: number;                  // 0.0-1.0
  colorTemperature: number;          // 2500-10000 Kelvin
  softness: number;                   // 0.0-1.0
  distance: number;                   // 0.5-5.0 meters
  enabled: boolean;                   // Light on/off
}
```

**Example Request:**
```json
{
  "subjectDescription": "professional model in studio",
  "environment": "minimalist photography studio with gray backdrop",
  "lightingSetup": {
    "key": {
      "direction": "45 degrees camera-right, elevated 30 degrees",
      "intensity": 0.8,
      "colorTemperature": 5600,
      "softness": 0.6,
      "distance": 1.5,
      "enabled": true
    },
    "fill": {
      "direction": "30 degrees camera-left",
      "intensity": 0.4,
      "colorTemperature": 5600,
      "softness": 0.7,
      "distance": 2.0,
      "enabled": true
    },
    "rim": {
      "direction": "behind subject camera-left",
      "intensity": 0.5,
      "colorTemperature": 3200,
      "softness": 0.3,
      "distance": 2.5,
      "enabled": true
    }
  },
  "cameraSettings": {
    "shotType": "medium shot",
    "cameraAngle": "eye-level",
    "fov": 85,
    "lensType": "portrait",
    "aperture": "f/2.8"
  },
  "stylePreset": "rembrandt",
  "enhanceHDR": true
}
```

**Response:**
```typescript
interface GenerationResponse {
  success: boolean;
  imageUrl: string;                   // URL to generated image
  seed: number;                        // Seed for reproducibility
  fiboJson: FIBOPrompt;                // Complete FIBO JSON used
  analysis: {
    keyFillRatio: number;              // Calculated ratio
    lightingStyle: string;             // Classified style
    professionalRating: number;        // 1-10 rating
    recommendations: string[];        // Improvement suggestions
  };
  metadata: {
    generationTime: number;            // Milliseconds
    model: string;                     // FIBO model version
    resolution: [number, number];      // Image dimensions
  };
}
```

**Error Response:**
```typescript
interface ErrorResponse {
  error: string;
  errorCode: string;                   // Machine-readable error code
  details?: string;                    // Additional error details
}
```

**Error Codes:**
- `METHOD_NOT_ALLOWED`: Request method not POST
- `MISSING_BODY`: Request body is empty
- `INVALID_JSON`: JSON parsing failed
- `MISSING_SUBJECT_DESCRIPTION`: Required field missing
- `MISSING_ENVIRONMENT`: Required field missing
- `INVALID_LIGHTING_SETUP`: Lighting configuration invalid
- `BRIA_API_ERROR`: BRIA API request failed
- `INTERNAL_ERROR`: Server-side error

#### Natural Language Generation

**Endpoint:** `POST /functions/v1/natural-language-lighting`

**Request Body:**
```typescript
interface NaturalLanguageRequest {
  sceneDescription: string;           // Required: Overall scene description
  lightingDescription: string;        // Required: Lighting description in natural language
  subject: string;                     // Required: Subject description
  styleIntent?: string;                // Optional: Style intent
  environment?: string;                // Optional: Environment override
}
```

**Example Request:**
```json
{
  "sceneDescription": "a professional fashion model in a luxury studio",
  "lightingDescription": "dramatic high-contrast lighting with strong rim light creating edge separation, warm key light from camera-right",
  "subject": "fashion model in evening dress",
  "styleIntent": "editorial fashion photography"
}
```

**Response:** Same as `generate-lighting` endpoint.

#### Lighting Analysis

**Endpoint:** `POST /functions/v1/analyze-lighting`

**Request Body:**
```typescript
interface AnalysisRequest {
  lightingSetup: {
    key?: LightSettings;
    fill?: LightSettings;
    rim?: LightSettings;
    ambient?: LightSettings;
  };
}
```

**Response:**
```typescript
interface AnalysisResponse {
  keyFillRatio: number;                // Calculated key-to-fill ratio
  lightingStyle: string;               // Classified style name
  professionalRating: number;          // 1-10 rating
  colorHarmony: {
    temperatureConsistency: number;    // 0-1 score
    mood: string;                       // Warm/cool/neutral
  };
  recommendations: string[];            // Improvement suggestions
  technicalNotes: string[];            // Technical observations
}
```

### Complete FIBO JSON Example

Here's a complete example of a FIBO JSON prompt for professional portrait photography:

```json
{
  "subject": {
    "main_entity": "professional model in evening dress",
    "attributes": ["elegant", "confident", "high fashion"],
    "action": "posing for editorial photograph",
    "emotion": "sophisticated",
    "mood": "luxurious"
  },
  "environment": {
    "setting": "minimalist photography studio with gray seamless backdrop",
    "time_of_day": "studio",
    "lighting_conditions": "professional studio lighting",
    "atmosphere": "clean and modern",
    "interior_style": "minimalist"
  },
  "camera": {
    "shot_type": "medium shot",
    "camera_angle": "eye-level",
    "fov": 85,
    "lens_type": "portrait",
    "aperture": "f/2.8",
    "focus_distance_m": 2.5,
    "pitch": 0,
    "yaw": 0,
    "roll": 0,
    "seed": 42
  },
  "lighting": {
    "main_light": {
      "direction": "45 degrees camera-right, elevated 30 degrees",
      "intensity": 0.8,
      "color_temperature": 5600,
      "softness": 0.6,
      "distance": 1.5,
      "falloff": "inverse_square"
    },
    "fill_light": {
      "direction": "30 degrees camera-left",
      "intensity": 0.4,
      "color_temperature": 5600,
      "softness": 0.7,
      "distance": 2.0,
      "falloff": "inverse_square"
    },
    "rim_light": {
      "direction": "behind subject camera-left",
      "intensity": 0.5,
      "color_temperature": 3200,
      "softness": 0.3,
      "distance": 2.5,
      "falloff": "inverse_square"
    },
    "ambient_light": {
      "intensity": 0.1,
      "color_temperature": 5500
    }
  },
  "color_palette": {
    "white_balance": "5600K",
    "mood": "neutral",
    "dominant_colors": ["gray", "white", "black"],
    "saturation": 1.0,
    "contrast": 1.2
  },
  "style_medium": "photograph",
  "artistic_style": "professional editorial fashion photography",
  "composition": {
    "rule_of_thirds": true,
    "depth_layers": 3,
    "framing": "centered"
  },
  "render": {
    "resolution": [1024, 1024],
    "color_space": "sRGB",
    "bit_depth": 8,
    "samples": 50
  },
  "enhancements": {
    "hdr": true,
    "professional_grade": true,
    "color_fidelity": true,
    "detail_enhancement": true,
    "noise_reduction": true
  },
  "negative_prompt": "blurry, distorted, low quality, artifacts"
}
```

### FIBO JSON Schema

The complete FIBO JSON schema structure:

```typescript
interface FIBOPrompt {
  subject: {
    main_entity: string;                // Primary subject
    attributes: string[];               // Subject attributes
    action?: string;                    // Subject action
    emotion?: string;                   // Emotional state
    mood?: string;                       // Overall mood
  };
  environment: {
    setting: string;                    // Environment description
    time_of_day?: string;               // Time of day
    lighting_conditions?: string;       // Lighting conditions
    atmosphere?: string;                 // Atmospheric description
    weather?: string;                    // Weather conditions (if outdoor)
    interior_style?: string;             // Interior style (if indoor)
  };
  camera: {
    shot_type: string;                  // Shot type
    camera_angle: string;               // Camera angle
    fov: number;                        // Field of view (10-180)
    lens_type: string;                  // Lens type
    aperture: string;                   // Aperture setting
    focus_distance_m?: number;          // Focus distance
    pitch?: number;                     // Pitch angle (-90 to 90)
    yaw?: number;                       // Yaw angle (-180 to 180)
    roll?: number;                      // Roll angle (-180 to 180)
    seed?: number;                      // Random seed
  };
  lighting: {
    main_light?: {
      direction: string;                // Photographic direction
      intensity: number;                // 0.0-1.0
      color_temperature: number;        // Kelvin (2500-10000)
      softness: number;                 // 0.0-1.0
      distance: number;                 // Meters
      falloff?: string;                 // Light falloff type
    };
    fill_light?: { /* same structure */ };
    rim_light?: { /* same structure */ };
    ambient_light?: {
      intensity: number;
      color_temperature: number;
    };
  };
  color_palette?: {
    white_balance: string;              // e.g., "5600K"
    mood: string;                       // Warm/cool/neutral
    dominant_colors?: string[];        // Color names
    saturation?: number;                // 0.0-2.0
    contrast?: number;                  // 0.0-2.0
  };
  style_medium?: string;                // e.g., "photograph"
  artistic_style?: string;              // Style description
  composition?: {
    rule_of_thirds?: boolean;
    depth_layers?: number | string[];
    framing?: string;
  };
  render?: {
    resolution?: [number, number];      // [width, height]
    color_space?: string;               // e.g., "sRGB"
    bit_depth?: number;                 // 8, 16, or 32
    samples?: number;                   // Render samples
  };
  enhancements?: {
    hdr?: boolean;                      // HDR enhancement
    professional_grade?: boolean;       // Professional processing
    color_fidelity?: boolean;           // Color accuracy
    detail_enhancement?: boolean;       // Detail enhancement
    noise_reduction?: boolean;           // Noise reduction
  };
  negative_prompt?: string;             // What to avoid
}
```

### TypeScript Client Example

```typescript
import { createClient } from '@supabase/supabase-js';

const supabase = createClient(
  import.meta.env.VITE_SUPABASE_URL,
  import.meta.env.VITE_SUPABASE_ANON_KEY
);

async function generateImage(lightingSetup: SceneRequest) {
  const { data, error } = await supabase.functions.invoke('generate-lighting', {
    body: lightingSetup,
  });

  if (error) {
    console.error('Generation error:', error);
    throw error;
  }

  return data;
}

// Usage
const result = await generateImage({
  subjectDescription: "professional model",
  environment: "studio",
  lightingSetup: {
    key: {
      direction: "45 degrees camera-right",
      intensity: 0.8,
      colorTemperature: 5600,
      softness: 0.6,
      distance: 1.5,
      enabled: true,
    },
  },
  cameraSettings: {
    shotType: "medium shot",
    cameraAngle: "eye-level",
    fov: 85,
    lensType: "portrait",
    aperture: "f/2.8",
  },
});

console.log('Generated image:', result.imageUrl);
console.log('Seed for reproducibility:', result.seed);
```

### Backend API Endpoints

The FastAPI backend provides additional endpoints:

#### Generate Endpoints
- `POST /api/generate` - Generate image from lighting setup
- `POST /api/generate/natural-language` - Generate from natural language description
- `POST /api/generate/from-preset` - Generate using a preset

#### Presets Endpoints
- `GET /api/presets` - List all available presets
- `GET /api/presets/{preset_id}` - Get specific preset details
- `GET /api/presets/categories` - List preset categories
- `POST /api/presets/search` - Search presets by criteria

#### History Endpoints
- `GET /api/history` - Get generation history (paginated)
- `GET /api/history/{generation_id}` - Get specific generation details
- `DELETE /api/history/{generation_id}` - Delete a generation
- `POST /api/history/clear` - Clear all history
- `GET /api/history/stats` - Get generation statistics

#### Batch Endpoints
- `POST /api/batch/generate` - Start batch generation job
- `GET /api/batch/{batch_id}` - Get batch job status
- `POST /api/batch/product-variations` - Generate product variations
- `GET /api/batch/{batch_id}/export` - Export batch results

#### Analysis Endpoints
- `POST /api/analyze/lighting` - Analyze lighting setup
- `POST /api/analyze/compare` - Compare two lighting setups
- `GET /api/analyze/recommendations/{style}` - Get style-specific recommendations

#### Video Editing Endpoints
- `POST /api/video-editing/jobs` - Create video editing job
- `GET /api/video-editing/jobs/{job_id}` - Get job status
- `GET /api/video-editing/subscribe/{job_id}` - SSE stream for real-time updates

#### Tailored Generation Endpoints
- `POST /api/tailored/projects` - Create tailored project
- `GET /api/tailored/projects` - List projects
- `POST /api/tailored/projects/{project_id}/datasets` - Create dataset
- `POST /api/tailored/datasets/{dataset_id}/images/register` - Register images
- `POST /api/tailored/models` - Create custom model
- `POST /api/tailored/models/{model_id}/generate` - Generate with custom model

### Python Client Example

```python
import requests

# Generate image from lighting setup
response = requests.post(
    "http://localhost:8000/api/generate",
    json={
        "subject_description": "professional model in studio",
        "environment": "minimalist photography studio",
        "lighting_setup": {
            "key": {
                "direction": "45 degrees camera-right, elevated 30 degrees",
                "intensity": 0.8,
                "color_temperature": 5600,
                "softness": 0.6,
                "distance": 1.5,
                "enabled": True
            },
            "fill": {
                "direction": "30 degrees camera-left",
                "intensity": 0.4,
                "color_temperature": 5600,
                "softness": 0.7,
                "distance": 2.0,
                "enabled": True
            }
        },
        "camera_settings": {
            "shot_type": "medium shot",
            "camera_angle": "eye-level",
            "fov": 85,
            "lens_type": "portrait",
            "aperture": "f/2.8"
        }
    }
)

result = response.json()
print(f"Generated image: {result['image_url']}")
print(f"Seed: {result['seed']}")
```

## üîß Development

### Project Structure

```
prolight-ai-fibo/
‚îú‚îÄ‚îÄ src/                          # Frontend source code
‚îÇ   ‚îú‚îÄ‚îÄ components/               # React components
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ui/                   # Reusable UI components (Radix UI)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lighting/             # Lighting control components
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ studio/               # Studio view components
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ generation/           # Image generation components
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ composition/          # Composition tools
‚îÇ   ‚îú‚îÄ‚îÄ pages/                    # Page components
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Studio.tsx            # Main studio interface
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ NaturalLanguage.tsx   # NL generation page
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ generate/             # Generation pages
‚îÇ   ‚îú‚îÄ‚îÄ hooks/                    # Custom React hooks
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ useGeneration.ts      # Image generation hook
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ useLighting.ts        # Lighting state hook
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ useBria.ts            # BRIA API integration
‚îÇ   ‚îú‚îÄ‚îÄ stores/                   # Zustand state stores
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ lightingStore.ts      # Lighting state management
‚îÇ   ‚îú‚îÄ‚îÄ utils/                    # Utility functions
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fiboMapper.ts         # FIBO JSON transformation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fiboValidation.ts     # FIBO schema validation
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ lightingCalculations.ts # Lighting math
‚îÇ   ‚îú‚îÄ‚îÄ types/                    # TypeScript type definitions
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ fibo.ts               # FIBO schema types
‚îÇ   ‚îú‚îÄ‚îÄ api/                      # API client functions
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ bria.ts               # BRIA API client
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ upload.ts              # Image upload utilities
‚îÇ   ‚îî‚îÄ‚îÄ App.tsx                   # Root component
‚îú‚îÄ‚îÄ supabase/
‚îÇ   ‚îú‚îÄ‚îÄ functions/                # Edge functions
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ generate-lighting/     # Main generation function
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ natural-language-lighting/ # NL to FIBO conversion
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ analyze-lighting/      # Lighting analysis
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ video-editing/         # Video editing function
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ _shared/               # Shared utilities
‚îÇ   ‚îî‚îÄ‚îÄ migrations/               # Database migrations
‚îú‚îÄ‚îÄ edge/                         # Edge function utilities
‚îÇ   ‚îî‚îÄ‚îÄ bria/                     # BRIA API wrappers
‚îú‚îÄ‚îÄ docs/                         # Documentation
‚îú‚îÄ‚îÄ public/                        # Static assets
‚îú‚îÄ‚îÄ vite.config.ts                 # Vite configuration
‚îú‚îÄ‚îÄ tsconfig.json                  # TypeScript configuration
‚îú‚îÄ‚îÄ tailwind.config.ts             # Tailwind CSS configuration
‚îî‚îÄ‚îÄ package.json                   # Dependencies
```

### Frontend Component Architecture

```mermaid
graph TB
    subgraph "Application Root"
        App[App Component<br/>ErrorBoundary + Providers]
    end
    
    subgraph "State Management Layer"
        Zustand[Zustand Stores]
        LightingStore[useLightingStore<br/>Lighting State]
        CameraStore[Camera Settings]
        SceneStore[Scene Configuration]
        GenerationStore[Generation Results]
    end
    
    subgraph "UI Components"
        MainLayout[MainLayout<br/>Navigation + Layout]
        StudioPage[Studio Page<br/>Main Interface]
        ControlsPanel[Lighting Controls Panel]
        Visualizer3D[3D Visualizer<br/>React Three Fiber]
        ImagePreview[Image Preview<br/>Generated Results]
        AnalysisDash[Analysis Dashboard<br/>Metrics & Ratings]
    end
    
    subgraph "Custom Hooks"
        useGeneration[useGeneration<br/>Image Generation Logic]
        useLighting[useLighting<br/>Lighting Calculations]
        useBria[useBria<br/>BRIA API Integration]
        useNaturalLanguage[useNaturalLanguage<br/>NL Processing]
    end
    
    subgraph "Utilities"
        FIBOMapper[FIBO Mapper<br/>JSON Transformation]
        FIBOValidator[FIBO Validator<br/>Schema Validation]
        LightingCalc[Lighting Calculations<br/>Ratios & Analysis]
    end
    
    App --> MainLayout
    MainLayout --> StudioPage
    StudioPage --> ControlsPanel
    StudioPage --> Visualizer3D
    StudioPage --> ImagePreview
    StudioPage --> AnalysisDash
    
    ControlsPanel --> LightingStore
    Visualizer3D --> LightingStore
    ImagePreview --> GenerationStore
    AnalysisDash --> GenerationStore
    
    useGeneration --> FIBOMapper
    useGeneration --> FIBOValidator
    useLighting --> LightingCalc
    
    LightingStore --> useGeneration
    LightingStore --> useLighting
    
    style Zustand fill:#e1f5ff
    style Visualizer3D fill:#fff4e1
    style useGeneration fill:#ffe1f5
```

### State Management

The application uses **Zustand** for state management with TypeScript for type safety:

```typescript
// src/stores/lightingStore.ts
import { create } from 'zustand';
import { devtools } from 'zustand/middleware';

interface Light {
  id: string;
  type: 'key' | 'fill' | 'rim' | 'ambient';
  enabled: boolean;
  intensity: number;
  kelvin: number;
  softness: number;
  distance: number;
  direction: [number, number, number]; // 3D vector
}

interface LightingState {
  lights: Light[];
  cameraSettings: CameraSettings;
  sceneDescription: string;
  addLight: (light: Light) => void;
  updateLight: (id: string, updates: Partial<Light>) => void;
  removeLight: (id: string) => void;
  // ... more actions
}

export const useLightingStore = create<LightingState>()(
  devtools(
    (set) => ({
      lights: [],
      cameraSettings: defaultCameraSettings,
      sceneDescription: '',
      addLight: (light) => set((state) => ({
        lights: [...state.lights, light]
      })),
      updateLight: (id, updates) => set((state) => ({
        lights: state.lights.map(l => 
          l.id === id ? { ...l, ...updates } : l
        )
      })),
      // ... more implementations
    }),
    { name: 'LightingStore' }
  )
);
```

### 3D Visualization Implementation

The 3D visualization uses React Three Fiber for real-time rendering:

```typescript
// src/components/studio/StudioVisualizer.tsx
import { Canvas } from '@react-three/fiber';
import { OrbitControls, Grid, Environment } from '@react-three/drei';
import { DirectionalLightHelper } from 'three';

function LightingScene() {
  const lights = useLightingStore((state) => state.lights);
  
  return (
    <Canvas camera={{ position: [0, 0, 5], fov: 50 }}>
      <ambientLight intensity={0.2} />
      {lights.map((light) => (
        <LightSource key={light.id} light={light} />
      ))}
      <Grid args={[10, 10]} />
      <OrbitControls />
      <Environment preset="studio" />
    </Canvas>
  );
}
```

### Running Tests

```bash
# Frontend tests (when implemented)
npm run test

# Type checking
npm run type-check

# Linting
npm run lint

# Build for production
npm run build

# Preview production build
npm run preview
```

### Code Quality

```bash
# ESLint
npm run lint

# TypeScript type checking
npx tsc --noEmit

# Format code (if Prettier is configured)
npm run format
```

### Development Workflow

1. **Feature Development:**
   ```bash
   git checkout -b feature/your-feature-name
   # Make changes
   npm run dev  # Start dev server
   # Test locally
   git commit -m "feat: add feature"
   git push origin feature/your-feature-name
   ```

2. **Edge Function Development:**
   ```bash
   # Test edge function locally
   supabase functions serve generate-lighting --env-file .env.local
   
   # Deploy to staging
   supabase functions deploy generate-lighting --project-ref staging-ref
   
   # Deploy to production
   supabase functions deploy generate-lighting --project-ref prod-ref
   ```

3. **Testing API Integration:**
   ```bash
   # Use curl or Postman to test endpoints
   curl -X POST http://localhost:54321/functions/v1/generate-lighting \
     -H "Content-Type: application/json" \
     -H "Authorization: Bearer $SUPABASE_ANON_KEY" \
     -d @test-request.json
   ```

## üéØ FIBO Integration Details

### Why FIBO?

- **JSON-Native Architecture**: Structured prompts instead of ambiguous text
- **Deterministic Control**: Reproducible results with same parameters + seed
- **Professional Parameters**: Camera, lighting, and composition controls
- **Commercial Licensing**: Fully licensed training data for commercial use
- **Type Safety**: Strongly typed schema with validation

### FIBO Repository Integration

This repository integrates with the official [Bria-AI/FIBO](https://github.com/Bria-AI/FIBO) repository for:
- **Local Development**: Run FIBO locally using the submodule
- **Schema Validation**: Generate Pydantic models from official JSON schemas
- **Code Examples**: Reference official implementations and examples

#### Setting Up FIBO Submodule

```bash
# Add FIBO as a git submodule
chmod +x scripts/add_fibo_submodule.sh
./scripts/add_fibo_submodule.sh

# This will clone the FIBO repository into libs/fibo
# Update the submodule later with:
git submodule update --remote libs/fibo
```

#### Generating Pydantic Models from Schema

```bash
# Generate type-safe Pydantic models from official FIBO JSON schema
chmod +x scripts/gen_pydantic_from_schema.sh
./scripts/gen_pydantic_from_schema.sh

# Or specify a custom schema URL:
./scripts/gen_pydantic_from_schema.sh <schema_url> backend/app
```

The generated models are available in `backend/app/models_fibo.py` and provide:
- Type validation for FIBO JSON prompts
- IDE autocomplete and type checking
- Schema documentation and examples

#### FIBO Adapter Architecture

The FIBO adapter (`backend/app/services/fibo_adapter.py`) supports three modes:

1. **Local FIBO** (preferred): Uses code from `libs/fibo` submodule if available
2. **Remote Bria API**: Falls back to Bria API when local code is unavailable
3. **Mock Mode**: For development/testing without API access

```python
from app.services.fibo_adapter import FIBOAdapter

adapter = FIBOAdapter()
# Automatically detects and uses local FIBO if available
result = await adapter.generate(fibo_prompt_json)
```

#### UI State to FIBO JSON Mapping

The `backend/app/ui_mapping.py` module converts frontend UI state to FIBO JSON:

```python
from app.ui_mapping import ui_to_fibo_json

ui_state = {
    "subject_text": "luxury watch",
    "camera": {"fov": 55, "aperture": 2.8},
    "lights": [
        {
            "id": "key",
            "pos": [0.5, 1.2, 0.8],
            "intensity": 0.9,
            "kelvin": 5600,
            "softness": 0.3
        }
    ],
    "render": {"resolution": [1024, 1024]}
}

fibo_json = ui_to_fibo_json(ui_state)
# Returns validated FIBO JSON prompt
```

### FIBO JSON Transformation Flow

The transformation from UI controls to FIBO JSON involves several steps:

1. **UI State Collection**: Gather lighting parameters from Zustand store
2. **Parameter Normalization**: Convert 3D vectors to photographic descriptions
3. **Schema Construction**: Build complete FIBO JSON structure
4. **Validation**: Validate against FIBO schema using Zod
5. **API Submission**: Send to BRIA FIBO API

```typescript
// src/utils/fiboMapper.ts
export function buildFiboPrompt(
  lightingSetup: LightingSetup,
  cameraSettings: CameraSettings,
  subjectDescription: string,
  environment: string
): FIBOPrompt {
  const lightingJson: Record<string, any> = {};
  
  // Convert each light to FIBO format
  for (const [type, settings] of Object.entries(lightingSetup)) {
    if (settings.enabled) {
      lightingJson[`${type}_light`] = {
        direction: vectorToPhotographicDescription(settings.direction),
        intensity: settings.intensity,
        color_temperature: settings.colorTemperature,
        softness: settings.softness,
        distance: settings.distance,
        falloff: "inverse_square"
      };
    }
  }
  
  return {
    subject: {
      main_entity: subjectDescription,
      attributes: ["professionally lit", "high quality"],
      action: "posed for professional photograph"
    },
    environment: {
      setting: environment,
      lighting_conditions: "professional studio"
    },
    camera: {
      shot_type: cameraSettings.shotType,
      camera_angle: cameraSettings.cameraAngle,
      fov: cameraSettings.fov,
      lens_type: cameraSettings.lensType,
      aperture: cameraSettings.aperture
    },
    lighting: lightingJson,
    style_medium: "photograph",
    artistic_style: "professional studio photography",
    enhancements: {
      hdr: true,
      professional_grade: true
    }
  };
}
```

### Natural Language to FIBO Conversion

The natural language processing uses Google Gemini AI with a specialized system prompt:

```typescript
// supabase/functions/natural-language-lighting/index.ts
const LIGHTING_SYSTEM_PROMPT = `You are a professional photography director and lighting expert with 20+ years of experience. Convert natural language lighting descriptions into precise, structured JSON parameters for AI image generation.

CRITICAL: Always output valid JSON with this exact structure. No additional text, no markdown.

{
  "lighting_setup": {
    "key": {"direction": "...", "intensity": 0.X, "colorTemperature": XXXX, "softness": 0.X, "distance": X.X, "enabled": true},
    "fill": {"direction": "...", "intensity": 0.X, "colorTemperature": XXXX, "softness": 0.X, "distance": X.X, "enabled": true},
    "rim": {"direction": "...", "intensity": 0.X, "colorTemperature": XXXX, "softness": 0.X, "distance": X.X, "enabled": true},
    "ambient": {"intensity": 0.X, "colorTemperature": XXXX, "enabled": true, "direction": "omnidirectional"}
  },
  "lighting_style": "...",
  "mood_description": "...",
  "shadow_intensity": 0.X
}

DIRECTION FORMAT: Use precise photographic terms:
- "45 degrees camera-right, elevated 30 degrees" 
- "directly above camera (butterfly position)"
- "90 degrees side (split lighting)"
- "behind subject camera-left (rim position)"

INTENSITY: 0.0-1.0 scale
- 0.1-0.3: Accent/subtle
- 0.4-0.6: Moderate
- 0.7-0.9: Strong
- 1.0: Maximum

COLOR TEMPERATURE (Kelvin):
- 2500-3200K: Warm tungsten/candlelight
- 3200-4000K: Warm white
- 4500-5000K: Cool white
- 5500-5800K: Daylight
- 6000-6500K: Cool daylight
- 7000-10000K: Blue sky/shade

SOFTNESS: 0.0-1.0
- 0.0-0.3: Hard light (small source, defined shadows)
- 0.4-0.6: Medium (moderate shadow transition)
- 0.7-1.0: Soft light (large source, gradual shadows)

CLASSIC LIGHTING PATTERNS:
- Butterfly/Paramount: Key directly above camera, creates butterfly shadow under nose
- Rembrandt: Key 45¬∞ side creating triangle of light on shadow-side cheek
- Loop: Key 30-45¬∞ creating small loop shadow from nose
- Split: Key 90¬∞ side, illuminating exactly half the face
- Broad: Key illuminating side of face closest to camera
- Short: Key illuminating side of face away from camera
- Clamshell: Key above + fill below, very flattering

Always set appropriate fill based on described mood:
- "Dramatic" = lower fill (0.1-0.3)
- "Soft/Flattering" = higher fill (0.4-0.6)
- "Flat/Commercial" = high fill (0.5-0.7)`;
```

### Lighting Parameter Mapping

The system maps 3D lighting parameters to FIBO JSON format:

| UI Parameter | FIBO Field | Transformation |
|-------------|------------|----------------|
| 3D Direction Vector `[x, y, z]` | `direction: string` | Convert to photographic description |
| Intensity `0.0-1.0` | `intensity: number` | Direct mapping |
| Color Temperature `2500-10000K` | `color_temperature: number` | Direct mapping |
| Softness `0.0-1.0` | `softness: number` | Direct mapping |
| Distance `0.5-5.0m` | `distance: number` | Direct mapping |
| Light Type | `{type}_light` key | Map to FIBO light type |

## üìä Performance Metrics

| Metric | Value | Target | Notes |
|--------|-------|--------|-------|
| **Image Generation Time** | 2-4 seconds | < 5 seconds | BRIA API response time |
| **3D Visualization FPS** | 60 FPS | > 30 FPS | React Three Fiber rendering |
| **API Response Time** | < 100ms | < 200ms | Edge function processing |
| **NL Processing Time** | 500ms-1s | < 2s | Gemini API response |
| **Bundle Size (gzipped)** | ~500KB | < 1MB | Production build |
| **Time to Interactive** | < 2s | < 3s | Initial page load |
| **Concurrent Users** | 100+ | 50+ | Edge function scaling |

### Performance Optimizations

1. **Code Splitting**: Route-based code splitting with React.lazy()
2. **Image Optimization**: Lazy loading and WebP format support
3. **State Management**: Zustand for minimal re-renders
4. **3D Rendering**: React Three Fiber with automatic batching
5. **API Caching**: TanStack Query for request caching
6. **Edge Computing**: Supabase Edge Functions for low latency

### System Performance Flow

```mermaid
graph TB
    subgraph "Client-Side Performance"
        A1[React Rendering<br/>~16ms per frame<br/>60 FPS target]
        A2[Three.js Rendering<br/>WebGL GPU acceleration]
        A3[State Updates<br/>Zustand store<br/>Minimal re-renders]
        A4[3D Calculations<br/>Light positioning<br/>Vector math]
    end
    
    subgraph "Network Layer"
        B1[HTTP Request<br/>Supabase Edge Function<br/>Deno runtime]
        B2[Request Size<br/>~5-10 KB JSON payload]
        B3[Response Time<br/>< 100ms initial processing]
    end
    
    subgraph "Server Processing"
        C1[JSON Transformation<br/>~10-20ms<br/>TypeScript execution]
        C2[Lighting Analysis<br/>~20-30ms<br/>Ratio calculations]
        C3[FIBO API Call<br/>2-4 seconds<br/>BRIA processing]
        C4[Image Processing<br/>~100-200ms<br/>URL generation]
    end
    
    subgraph "External Services"
        D1[BRIA FIBO API<br/>Image Generation<br/>Stable Diffusion backend]
        D2[Gemini AI<br/>NL Processing<br/>~500ms-1s response]
    end
    
    A1 --> A2
    A3 --> A4
    A4 --> B1
    
    B1 --> B2
    B2 --> C1
    
    C1 --> C2
    C2 --> C3
    C3 --> D1
    C2 --> D2
    
    D1 --> C4
    D2 --> C1
    
    C4 --> B3
    B3 --> A1
    
    style A2 fill:#e1ffe1
    style C3 fill:#fff4e1
    style D1 fill:#ffe1f5
```

## üöÄ Deployment

### Frontend Deployment (Vercel)

```bash
# Install Vercel CLI
npm i -g vercel

# Login to Vercel
vercel login

# Deploy to production
vercel --prod

# Or connect GitHub repo for automatic deployments
# 1. Go to Vercel dashboard
# 2. Import your GitHub repository
# 3. Configure build settings:
#    - Build Command: npm run build
#    - Output Directory: dist
#    - Install Command: npm install
```

**Vercel Environment Variables:**
- `VITE_SUPABASE_URL` - Your Supabase project URL
- `VITE_SUPABASE_ANON_KEY` - Your Supabase anonymous key
- `VITE_API_URL` - Backend API URL (if using separate backend)

### Backend Deployment

#### Option 1: Railway

```bash
# Install Railway CLI
npm i -g @railway/cli

# Login
railway login

# Initialize project
railway init

# Link to existing project
railway link

# Deploy
railway up
```

#### Option 2: Docker

```bash
# Build Docker image
cd backend
docker build -t prolight-ai-backend .

# Run container
docker run -d \
  -p 8000:8000 \
  -e FIBO_API_KEY=your_key \
  -e DATABASE_URL=your_database_url \
  prolight-ai-backend
```

#### Option 3: Heroku

```bash
# Install Heroku CLI
# Login to Heroku
heroku login

# Create app
heroku create prolight-ai-backend

# Set environment variables
heroku config:set FIBO_API_KEY=your_key
heroku config:set DATABASE_URL=your_database_url

# Deploy
git push heroku main
```

### Edge Functions Deployment

```bash
# Deploy all functions
supabase functions deploy generate-lighting
supabase functions deploy natural-language-lighting
supabase functions deploy analyze-lighting
supabase functions deploy video-editing
supabase functions deploy tailored-generation
supabase functions deploy poll-jobs

# Set environment secrets
supabase secrets set BRIA_API_KEY=your_key
supabase secrets set GEMINI_API_KEY=your_key

# Deploy to specific project
supabase functions deploy generate-lighting --project-ref your-project-ref
```

### Worker Deployment

The worker can be deployed as:
- **Cron Job**: Set up a cron job to run periodically
- **Cloud Function**: Deploy to AWS Lambda, Google Cloud Functions, etc.
- **Docker Container**: Run as a background service
- **Supabase pg_cron**: Use PostgreSQL cron extension

Example cron job:
```bash
# Run every 5 minutes
*/5 * * * * cd /path/to/prolight-ai-fibo/worker && node worker.js
```

### Database Migrations

```bash
# Run migrations
cd backend
alembic upgrade head

# Create new migration
alembic revision --autogenerate -m "description"

# Apply migration
alembic upgrade head
```

### Environment Configuration

Set the following environment variables in your deployment platform:

- `VITE_SUPABASE_URL`: Your Supabase project URL
- `VITE_SUPABASE_ANON_KEY`: Your Supabase anonymous key
- `BRIA_API_KEY`: BRIA API key (edge function secret)
- `GEMINI_API_KEY`: Google Gemini API key (edge function secret)

## üîí Security Considerations

1. **API Key Protection**: All API keys stored as Supabase secrets, never exposed to client
2. **CORS Configuration**: Proper CORS headers in edge functions
3. **Input Validation**: Zod schema validation on all inputs
4. **Rate Limiting**: Implement rate limiting for API endpoints
5. **Error Handling**: Sanitized error messages (no sensitive data exposure)
6. **Type Safety**: TypeScript for compile-time safety
7. **Environment Variables**: Never commit `.env` files to version control
8. **HTTPS Only**: All production endpoints should use HTTPS
9. **Authentication**: Implement user authentication for production use
10. **Input Sanitization**: Sanitize all user inputs to prevent injection attacks

### Security Best Practices

- **Never expose API keys** in client-side code
- **Use environment variables** for all sensitive configuration
- **Validate all inputs** on both client and server
- **Implement rate limiting** to prevent abuse
- **Use HTTPS** for all API communications
- **Regular security audits** of dependencies
- **Keep dependencies updated** to patch vulnerabilities

## üí° Use Cases

### Professional Photography
- **Portrait Photography**: Create perfect studio lighting for portraits
- **Product Photography**: Generate consistent product shots with professional lighting
- **Fashion Photography**: Experiment with dramatic lighting setups
- **Commercial Photography**: Create high-quality commercial images

### Content Creation
- **Social Media**: Generate eye-catching images for social media posts
- **Marketing Materials**: Create professional marketing images
- **Blog Posts**: Generate featured images with custom lighting
- **E-commerce**: Create product images with consistent lighting

### Education & Training
- **Photography Education**: Learn lighting principles through experimentation
- **Workshop Demonstrations**: Show different lighting setups in real-time
- **Portfolio Building**: Create diverse portfolio pieces with various lighting styles

### Research & Development
- **Lighting Research**: Study the effects of different lighting parameters
- **Algorithm Testing**: Test image generation algorithms with controlled inputs
- **A/B Testing**: Compare different lighting setups for optimization

## ‚ùì Frequently Asked Questions

### General Questions

**Q: What is FIBO?**  
A: FIBO (Fine-grained Image Boosting Optimization) is BRIA AI's JSON-native architecture for structured image generation. It replaces ambiguous text prompts with precise, reproducible parameters.

**Q: How is this different from other AI image generators?**  
A: ProLight AI provides deterministic control through structured JSON parameters. Same parameters + seed = identical output every time, unlike text-based generators that produce variable results.

**Q: Do I need expensive equipment?**  
A: No! ProLight AI simulates professional studio lighting setups digitally, allowing you to create perfect lighting without physical equipment.

**Q: Can I use this commercially?**  
A: Yes, BRIA FIBO is fully licensed for commercial use. Check BRIA AI's licensing terms for specific details.

### Technical Questions

**Q: What programming languages are used?**  
A: The frontend uses TypeScript/React, backend uses Python/FastAPI, and edge functions use TypeScript/Deno.

**Q: How long does image generation take?**  
A: Typically 2-4 seconds per image, depending on BRIA API response time and image complexity.

**Q: Can I run this locally?**  
A: Yes! See the [Installation](#Ô∏è-installation) section for local development setup instructions.

**Q: What are the system requirements?**  
A: 
- **Frontend**: Modern browser with WebGL support (Chrome, Firefox, Safari, Edge)
- **Backend**: Python 3.11+, Node.js 18+ (for edge functions)
- **Storage**: ~500MB for dependencies

**Q: How do I get API keys?**  
A: 
- **BRIA API**: Sign up at [bria.ai](https://www.bria.ai/) and get your API key
- **Gemini API**: Get your key from [Google AI Studio](https://makersuite.google.com/app/apikey)
- **Supabase**: Create a project at [supabase.com](https://supabase.com)

### Troubleshooting

**Q: Images aren't generating. What's wrong?**  
A: 
1. Check that your BRIA API key is correctly set
2. Verify your internet connection
3. Check browser console for error messages
4. Ensure edge functions are deployed and accessible

**Q: 3D visualization isn't working.**  
A: 
1. Ensure your browser supports WebGL
2. Check browser console for WebGL errors
3. Try a different browser
4. Update your graphics drivers

**Q: Backend won't start.**  
A: 
1. Verify Python version (3.11+)
2. Check that all dependencies are installed
3. Ensure port 8000 is not in use
4. Check `.env` file configuration

**Q: Edge functions return errors.**  
A: 
1. Verify Supabase secrets are set correctly
2. Check edge function logs in Supabase dashboard
3. Ensure functions are deployed to the correct project
4. Verify API keys are valid

### Feature Questions

**Q: Can I save my lighting setups?**  
A: Yes! Use the presets feature to save and reuse your favorite lighting configurations.

**Q: Can I generate multiple images at once?**  
A: Yes! Use the batch generation feature to create multiple variations.

**Q: How do I use natural language input?**  
A: Navigate to the "Natural Language" tab and describe your desired lighting setup in plain English. The system will convert it to structured parameters.

**Q: What lighting presets are available?**  
A: We include 6+ professional presets: Butterfly, Rembrandt, Loop, Split, Product Three-Point, and Golden Hour Window.

**Q: Can I train custom models?**  
A: Yes! Use the tailored generation feature to train models on your own image datasets.

## ü§ù Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.

### Development Workflow

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Make your changes with proper TypeScript types
4. Write/update tests if applicable
5. Commit your changes (`git commit -m 'feat: add amazing feature'`)
6. Push to the branch (`git push origin feature/amazing-feature`)
7. Open a Pull Request

### Code Standards

- **TypeScript**: Strict type checking enabled
- **ESLint**: Follow project ESLint configuration
- **Code Style**: Use Prettier for formatting (if configured)
- **Commits**: Use conventional commit messages
- **Documentation**: Update README and code comments for new features

### Testing Checklist

- [ ] TypeScript compilation passes (`npm run type-check`)
- [ ] ESLint passes (`npm run lint`)
- [ ] Manual testing in development environment
- [ ] Edge function testing with local Supabase
- [ ] API integration testing

## üìö Additional Documentation

### Core Documentation
- **[FIBO Parameter Reference](./docs/FIBO_PARAMETER_REFERENCE.md)** - Complete FIBO schema documentation
- **[Deployment Guide](./docs/DEPLOYMENT.md)** - Detailed deployment instructions
- **[Setup Guide](./docs/SETUP.md)** - Development environment setup
- **[Hackathon Submission](./docs/HACKATHON_SUBMISSION.md)** - Hackathon submission details
- **[Project Structure](./docs/PROJECT_STRUCTURE.md)** - Detailed project organization

### Integration Guides
- **[BRIA Integration Guide](./docs/BRIA_INTEGRATION_GUIDE.md)** - Complete BRIA API integration
- **[BRIA Image Generation V2](./docs/BRIA_IMAGE_GENERATION_V2_INTEGRATION.md)** - Image generation API
- **[BRIA Ads V1 Integration](./docs/BRIA_ADS_V1_INTEGRATION.md)** - Advertisement generation
- **[ControlNet Integration](./docs/CONTROLNET_INTEGRATION_GUIDE.md)** - ControlNet guidance
- **[Video Editing Integration](./VIDEO_EDITING_QUICKSTART.md)** - Video editing features

### Architecture & Improvements
- **[FIBO Architecture Improvements](./docs/FIBO_ARCHITECTURE_IMPROVEMENTS.md)** - Architecture enhancements
- **[Edge Functions Improvements](./docs/EDGE_FUNCTIONS_IMPROVEMENTS.md)** - Edge function optimizations
- **[Frontend Enhancements](./FRONTEND_ENHANCEMENTS.md)** - Frontend improvements

### Backend Documentation
- **[Backend README](./backend/README.md)** - Backend setup and API documentation
- **[Backend Environment Setup](./backend/ENV_SETUP.md)** - Environment configuration

### Quick References
- **[Lovable Edge Quick Reference](./docs/LOVABLE_EDGE_QUICK_REFERENCE.md)** - Edge function quick reference
- **[FIBO Integration](./docs/FIBO_INTEGRATION.md)** - FIBO integration details

## üìä Project Statistics

### Codebase Metrics
- **Frontend**: ~200+ TypeScript/React files
- **Backend**: ~50+ Python files
- **Edge Functions**: 6+ Deno/TypeScript functions
- **Total Lines of Code**: ~50,000+
- **Test Coverage**: Backend tests included
- **Documentation**: Comprehensive docs in `/docs` directory

### Technology Adoption
- **TypeScript**: 100% type coverage in frontend
- **Python**: Type hints throughout backend
- **Modern React**: Hooks, Context, and modern patterns
- **Edge Computing**: Deno runtime for low latency
- **3D Graphics**: Three.js for real-time visualization

### API Endpoints
- **Frontend API**: 20+ endpoints
- **Backend API**: 30+ endpoints
- **Edge Functions**: 6+ serverless functions
- **Total Endpoints**: 50+ API endpoints

## ü§ù Community & Support

### Getting Help
- **GitHub Issues**: Report bugs and request features
- **Discussions**: Ask questions and share ideas
- **Documentation**: Comprehensive guides in `/docs`
- **Examples**: Check `/integration_examples` for code samples

### Contributing Guidelines

We welcome contributions! Here's how you can help:

1. **Report Bugs**: Open an issue with detailed information
2. **Suggest Features**: Share your ideas for improvements
3. **Submit PRs**: Follow our coding standards and test your changes
4. **Improve Documentation**: Help make the docs better
5. **Share Examples**: Add examples of how you're using ProLight AI

### Code of Conduct

We are committed to providing a welcoming and inclusive environment. Please be respectful and constructive in all interactions.

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

### Third-Party Licenses

- **BRIA FIBO**: Commercial license from BRIA AI
- **React**: MIT License
- **Three.js**: MIT License
- **FastAPI**: MIT License
- **Supabase**: Apache 2.0 License

Please review individual package licenses in `package.json` and `requirements.txt`.

## üôè Acknowledgments

### Core Technologies
- **BRIA AI** for the FIBO model and API access - enabling structured, deterministic image generation
- **Google Gemini** for natural language processing capabilities - converting descriptions to structured parameters
- **Three.js** community for 3D graphics components - real-time lighting visualization
- **Supabase** for edge functions and infrastructure - serverless backend capabilities
- **React** and **TypeScript** communities for excellent tooling and developer experience

### Libraries & Frameworks
- **FastAPI** - High-performance Python web framework
- **Vite** - Next-generation frontend build tool
- **Zustand** - Lightweight state management
- **TanStack Query** - Powerful data synchronization
- **Radix UI** - Accessible component primitives
- **Tailwind CSS** - Utility-first CSS framework
- **Framer Motion** - Production-ready motion library
- **React Three Fiber** - React renderer for Three.js

### Inspiration
- Professional photographers who inspired the lighting control system
- The open-source community for continuous improvement
- Hackathon organizers for creating the opportunity to build this project

## üèÜ Hackathon Submission

This project was created for the **FIBO Hackathon 2025** and demonstrates:

- ‚úÖ **Innovative Use of FIBO**: JSON-native parameter control for deterministic results
- ‚úÖ **Professional Application**: Solves real photography workflow problems
- ‚úÖ **Technical Excellence**: Full-stack TypeScript implementation with edge computing
- ‚úÖ **User Experience**: Intuitive interface with real-time 3D feedback
- ‚úÖ **Production Ready**: Error handling, validation, and comprehensive documentation

## üêõ Troubleshooting

### Common Issues and Solutions

#### Frontend Issues

**Problem: Application won't start**
```bash
# Clear node_modules and reinstall
rm -rf node_modules package-lock.json
npm install

# Check Node.js version (requires 18+)
node --version

# Clear Vite cache
rm -rf node_modules/.vite
```

**Problem: 3D visualization not rendering**
- Check browser WebGL support: Visit [get.webgl.org](https://get.webgl.org/)
- Update graphics drivers
- Try a different browser (Chrome, Firefox, Safari)
- Check browser console for WebGL errors

**Problem: API calls failing**
- Verify `VITE_SUPABASE_URL` and `VITE_SUPABASE_ANON_KEY` are set
- Check network tab in browser DevTools
- Verify CORS configuration on backend
- Check Supabase project is active

#### Backend Issues

**Problem: Backend won't start**
```bash
# Check Python version (requires 3.11+)
python --version

# Reinstall dependencies
pip install -r requirements.txt --force-reinstall

# Check port availability
lsof -i :8000  # macOS/Linux
netstat -ano | findstr :8000  # Windows

# Use different port
uvicorn app.main:app --port 8001
```

**Problem: Database connection errors**
- Verify `DATABASE_URL` in `.env` file
- Check database is running (if using local PostgreSQL)
- Verify database credentials
- Check network connectivity

**Problem: FIBO API errors**
- Verify `FIBO_API_KEY` is set correctly
- Check API key is valid and not expired
- Set `USE_MOCK_FIBO=True` for testing without API
- Check BRIA API status page

#### Edge Function Issues

**Problem: Edge functions return 500 errors**
```bash
# Check function logs
supabase functions logs generate-lighting

# Verify secrets are set
supabase secrets list

# Test function locally
supabase functions serve generate-lighting --env-file .env.local
```

**Problem: CORS errors**
- Verify CORS headers in edge function code
- Check `Access-Control-Allow-Origin` header
- Ensure frontend URL is in allowed origins

#### Docker Issues

**Problem: Docker containers won't start**
```bash
# Check Docker is running
docker ps

# Rebuild containers
docker-compose down
docker-compose build --no-cache
docker-compose up -d

# View logs
docker-compose logs -f
```

**Problem: Port conflicts**
- Edit `docker-compose.yml` to use different ports
- Stop conflicting services
- Check what's using the ports: `lsof -i :8000`

### Getting Help

If you encounter issues not covered here:

1. **Check the logs**: Frontend (browser console), Backend (terminal), Edge Functions (Supabase dashboard)
2. **Review documentation**: See [Additional Documentation](#-additional-documentation)
3. **Search issues**: Check GitHub issues for similar problems
4. **Create an issue**: Provide error messages, logs, and steps to reproduce

### Debug Mode

Enable debug mode for more detailed error messages:

**Frontend:**
```typescript
// In vite.config.ts or .env
VITE_DEBUG=true
```

**Backend:**
```python
# In .env
DEBUG=True
```

**Edge Functions:**
```typescript
// Add console.log statements
console.log('Debug:', JSON.stringify(data, null, 2));
```

---

<div align="center">

**ProLight AI** - *Precision Lighting, Powered by FIBO*

[Report Bug](https://github.com/your-username/prolight-ai-fibo/issues) ‚Ä¢ [Request Feature](https://github.com/your-username/prolight-ai-fibo/issues) ‚Ä¢ [Documentation](./docs/)

Made with ‚ù§Ô∏è for the FIBO Hackathon 2025

</div>
